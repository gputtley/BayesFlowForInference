num_coupling_layer: 4
units_per_coupling_layer: 32
num_dense_layers: 2
activation: "relu"
dropout: True
mc_dropout: True
epochs: 10
batch_size: 64
early_stopping: True
learning_rate: 0.001
coupling_design: "affine"
permutation: "learnable"
optimizer_name: "Adam"
lr_scheduler_name: "ExponentialDecay"
lr_scheduler_options:
  decay_rate: 0.5