num_coupling_layers:
  - 4
units_per_coupling_layer:
  - 128
num_dense_layers:
  - 4
activation: 
  - "relu"
dropout: 
  - False
mc_dropout: 
  - False
epochs: 30
batch_size: 
  - 32
  - 64
  - 128
early_stopping: True
learning_rate: 
  - 0.001
  - 0.005
  - 0.01
coupling_design: "interleaved"
permutation: 
  - "fixed"
optimizer_name: 
  - "Adam"
lr_scheduler_name: "ExponentialDecay"
lr_scheduler_options:
  decay_rate: 
  - 0.5
  - 0.8
  - 0.9